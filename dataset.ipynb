{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO6/MQqWuFu3SNAE3WSJ/VN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ux-SzUJ9uHL8","executionInfo":{"status":"ok","timestamp":1659631120356,"user_tz":-330,"elapsed":3850,"user":{"displayName":"Yash Soni","userId":"10568387452058295479"}}},"outputs":[],"source":["from pathlib import Path\n","\n","import torch\n","import numpy as np\n","import imgaug\n","import imgaug.augmenters as iaa\n","from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n","\n","class CardiacDataset(torch.utils.data.Dataset):\n","    def __init__(self, root, augment_params):\n","        self.all_files = self.extract_files(root)\n","        self.augment_params = augment_params\n","    \n","    @staticmethod\n","    def extract_files(root):\n","        \"\"\"\n","        Extract the paths to all slices given the root path (ends with train or val)\n","        \"\"\"\n","        files = []\n","        for subject in root.glob(\"*\"):   # Iterate over the subjects\n","            slice_path = subject/\"data\"  # Get the slices for current subject\n","            for slice in slice_path.glob(\"*\"):\n","                files.append(slice)\n","        return files\n","    \n","    \n","    @staticmethod\n","    def change_img_to_label_path(path):\n","        \"\"\"\n","        Replace data with mask to get the masks\n","        \"\"\"\n","        parts = list(path.parts)\n","        parts[parts.index(\"data\")] = \"masks\"\n","        return Path(*parts)\n","\n","    def augment(self, slice, mask):\n","        \"\"\"\n","        Augments slice and segmentation mask in the exact same way\n","        Note the manual seed initialization\n","        \"\"\"\n","        ###################IMPORTANT###################\n","        # Fix for https://discuss.pytorch.org/t/dataloader-workers-generate-the-same-random-augmentations/28830/2\n","        random_seed = torch.randint(0, 1000000, (1,))[0].item()\n","        imgaug.seed(random_seed)\n","        #####################################################\n","        mask = SegmentationMapsOnImage(mask, mask.shape)\n","        slice_aug, mask_aug = self.augment_params(image=slice, segmentation_maps=mask)\n","        mask_aug = mask_aug.get_arr()\n","        return slice_aug, mask_aug\n","    \n","    def __len__(self):\n","        \"\"\"\n","        Return the length of the dataset (length of all files)\n","        \"\"\"\n","        return len(self.all_files)\n","    \n","    \n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Given an index return the (augmented) slice and corresponding mask\n","        Add another dimension for pytorch\n","        \"\"\"\n","        file_path = self.all_files[idx]\n","        mask_path = self.change_img_to_label_path(file_path)\n","        slice = np.load(file_path).astype(np.float32)\n","        mask = np.load(mask_path)\n","        \n","        if self.augment_params:\n","            slice, mask = self.augment(slice, mask)\n","        \n","        return np.expand_dims(slice, 0), np.expand_dims(mask, 0)\n","        "]}]}